{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3012302d",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c37c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root (parent of notebooks/)\n",
    "ROOT = Path.cwd().parents[0]\n",
    "\n",
    "# Add root to path if not present\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "# Define paths used in the pipeline\n",
    "DATA_TRAIN   = ROOT / \"data\" / \"interim\" / \"training_fe.csv\"\n",
    "DATA_LABELS  = ROOT / \"data\" / \"raw\" / \"training_set_labels.csv\"\n",
    "\n",
    "ARTIFACTS    = ROOT / \"artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf521c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts will be saved to: c:\\Projects\\Flushot\\artifacts\\model_comparison\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import utility functions from src\n",
    "from src.modeling import load_training_data, compute_metrics, save_confusion_matrices, TARGET_COLS\n",
    "# ARTIFACTS = ROOT / \"artifacts\"\n",
    "ARTIFACTS_COMPARISON = ARTIFACTS / \"model_comparison\"\n",
    "ARTIFACTS_COMPARISON.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Artifacts will be saved to: {ARTIFACTS_COMPARISON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdee01",
   "metadata": {},
   "source": [
    "### Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d443b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training shape: (21365, 72)\n",
      "Validation shape: (5342, 72)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "X, y = load_training_data(str(DATA_TRAIN), str(DATA_LABELS))\n",
    "# Split into train and validation sets (80% train, 20% validation)\n",
    "# We use a fixed random state for reproducibility\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training shape: {X_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5437d70",
   "metadata": {},
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6e8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to compare\n",
    "models_config = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbb17c",
   "metadata": {},
   "source": [
    "### Train, Evaluate, and Collect Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7044d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model comparison...\n",
      "\n",
      "=== Target: h1n1_vaccine ===\n",
      "Training Logistic Regression...\n",
      "  Logistic Regression ROC-AUC: 0.8622\n",
      "Training Random Forest...\n",
      "  Random Forest ROC-AUC: 0.8645\n",
      "Training LightGBM...\n",
      "  LightGBM ROC-AUC: 0.8705\n",
      "\n",
      "=== Target: seasonal_vaccine ===\n",
      "Training Logistic Regression...\n",
      "  Logistic Regression ROC-AUC: 0.8564\n",
      "Training Random Forest...\n",
      "  Random Forest ROC-AUC: 0.8562\n",
      "Training LightGBM...\n",
      "  LightGBM ROC-AUC: 0.8636\n",
      "\n",
      "Comparison complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize storage for results\n",
    "comparison_results = []\n",
    "print(\"Starting model comparison...\")\n",
    "for target in TARGET_COLS:\n",
    "    print(f\"\\n=== Target: {target} ===\")\n",
    "    y_train_target = y_train[target]\n",
    "    y_val_target = y_val[target]\n",
    "    \n",
    "    for model_name, model in models_config.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train_target)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics = compute_metrics(y_val_target, y_pred, y_prob)\n",
    "        \n",
    "        # Add to results\n",
    "        result_entry = {\n",
    "            \"Target\": target,\n",
    "            \"Model\": model_name,\n",
    "            **metrics\n",
    "        }\n",
    "        comparison_results.append(result_entry)\n",
    "        \n",
    "        # Save confusion matrices\n",
    "        # Filename safe model name\n",
    "        safe_model_name = model_name.replace(\" \", \"_\").lower()\n",
    "        save_confusion_matrices(\n",
    "            y_val_target, \n",
    "            y_pred, \n",
    "            f\"{target}_{safe_model_name}\", \n",
    "            str(ARTIFACTS_COMPARISON)\n",
    "        )\n",
    "        \n",
    "        print(f\"  {model_name} ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "print(\"\\nComparison complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb498e0",
   "metadata": {},
   "source": [
    "### Create Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad99ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison Table ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h1n1_vaccine</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.853613</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.488496</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.862170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1n1_vaccine</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.848559</td>\n",
       "      <td>0.740630</td>\n",
       "      <td>0.437168</td>\n",
       "      <td>0.549805</td>\n",
       "      <td>0.864452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h1n1_vaccine</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.854549</td>\n",
       "      <td>0.719255</td>\n",
       "      <td>0.512389</td>\n",
       "      <td>0.598450</td>\n",
       "      <td>0.870486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seasonal_vaccine</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>0.753162</td>\n",
       "      <td>0.766134</td>\n",
       "      <td>0.856361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seasonal_vaccine</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.779671</td>\n",
       "      <td>0.768324</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.756062</td>\n",
       "      <td>0.856206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seasonal_vaccine</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.787346</td>\n",
       "      <td>0.772031</td>\n",
       "      <td>0.761322</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.863632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Target                Model  accuracy  precision    recall  \\\n",
       "0      h1n1_vaccine  Logistic Regression  0.853613   0.730159  0.488496   \n",
       "1      h1n1_vaccine        Random Forest  0.848559   0.740630  0.437168   \n",
       "2      h1n1_vaccine             LightGBM  0.854549   0.719255  0.512389   \n",
       "3  seasonal_vaccine  Logistic Regression  0.789030   0.779561  0.753162   \n",
       "4  seasonal_vaccine        Random Forest  0.779671   0.768324  0.744186   \n",
       "5  seasonal_vaccine             LightGBM  0.787346   0.772031  0.761322   \n",
       "\n",
       "         f1   roc_auc  \n",
       "0  0.585366  0.862170  \n",
       "1  0.549805  0.864452  \n",
       "2  0.598450  0.870486  \n",
       "3  0.766134  0.856361  \n",
       "4  0.756062  0.856206  \n",
       "5  0.766639  0.863632  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame from results\n",
    "df_results = pd.DataFrame(comparison_results)\n",
    "# Display the table\n",
    "print(\"\\n=== Model Comparison Table ===\")\n",
    "display(df_results)\n",
    "# Save table to CSV\n",
    "df_results.to_csv(ARTIFACTS_COMPARISON / \"model_comparison_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32192442",
   "metadata": {},
   "source": [
    "### Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d74a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best Models (based on ROC-AUC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h1n1_vaccine</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.870486</td>\n",
       "      <td>0.598450</td>\n",
       "      <td>0.719255</td>\n",
       "      <td>0.512389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seasonal_vaccine</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.863632</td>\n",
       "      <td>0.766639</td>\n",
       "      <td>0.772031</td>\n",
       "      <td>0.761322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Target     Model   roc_auc        f1  precision    recall\n",
       "2      h1n1_vaccine  LightGBM  0.870486  0.598450   0.719255  0.512389\n",
       "5  seasonal_vaccine  LightGBM  0.863632  0.766639   0.772031  0.761322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for h1n1_vaccine: LightGBM (ROC-AUC: 0.8705)\n",
      "Best model for seasonal_vaccine: LightGBM (ROC-AUC: 0.8636)\n"
     ]
    }
   ],
   "source": [
    "# Identify best model for each target based on ROC-AUC\n",
    "print(\"\\n=== Best Models (based on ROC-AUC) ===\")\n",
    "best_models_summary = df_results.loc[df_results.groupby(\"Target\")[\"roc_auc\"].idxmax()]\n",
    "display(best_models_summary[[\"Target\", \"Model\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]])\n",
    "for _, row in best_models_summary.iterrows():\n",
    "    print(f\"Best model for {row['Target']}: {row['Model']} (ROC-AUC: {row['roc_auc']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ba3d2",
   "metadata": {},
   "source": [
    "### Candidate Models & Performance\n",
    "We evaluated three distinct architectures to identify the optimal model:\n",
    "*   **Logistic Regression**: Linear baseline.\n",
    "*   **Random Forest**: Non-linear bagging ensemble.\n",
    "*   **LightGBM**: Gradient boosting framework.\n",
    "\n",
    "**Result**: LightGBM outperformed baselines on the validation set for both targets using the **ROC-AUC** metric.\n",
    "\n",
    "| Target | Model | ROC-AUC | Lift vs LogReg |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **H1N1 Vaccine** | **LightGBM** | **0.8705** | +0.83% |\n",
    "| **Seasonal Flu** | **LightGBM** | **0.8636** | +0.72% |\n",
    "\n",
    "### Why ROC-AUC & LightGBM?\n",
    "\n",
    "#### The Challenge: Imbalance\n",
    "*   **H1N1** is effectively imbalanced (**21%** positive / 79% negative).\n",
    "*   **Seasonal Flu** is balanced (**47%** positive / 53% negative).\n",
    "*   *Selection Metric*: **ROC-AUC** was chosen over Accuracy/F1 because it is threshold-independent and robust to imbalance, ensuring the model prioritizes ranking actual positive cases higher rather than just maximizing majority class accuracy.\n",
    "\n",
    "#### The Solution: LightGBM\n",
    "*   **Boosting Mechanism**: By training sequentially on residuals, LightGBM naturally focuses learning on \"hard\" examples (often the minority positive class in H1N1), improving discrimination where others fail.\n",
    "*   **Interpretability (SHAP)**: LightGBM supports **TreeSHAP**, enabling the computation of *exact* feature contributions (Shapley values). This is critical for explaining *why* specific demographics are predicted as high-affinity for the vaccine, ensuring actionable and trustworthy insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
